{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# tensorflow is a library for fast tensor manipulation\n",
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "# num_words means you'll only keep the top 10,000 most frequently occuring words in the training data\n",
    "# rare words will be discarded\n",
    "# this allows to work with vector data of manageable size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict(\n",
    "    [(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join(\n",
    "    [reverse_word_index.get(i-3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the network\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tells the network what optimizer to use\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 3s 179us/step - loss: 0.5078 - acc: 0.7828 - val_loss: 0.3796 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 2s 133us/step - loss: 0.3005 - acc: 0.9053 - val_loss: 0.3001 - val_acc: 0.8906\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 2s 127us/step - loss: 0.2178 - acc: 0.9282 - val_loss: 0.3079 - val_acc: 0.8721\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 2s 127us/step - loss: 0.1750 - acc: 0.9436 - val_loss: 0.2838 - val_acc: 0.8838\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 2s 125us/step - loss: 0.1425 - acc: 0.9541 - val_loss: 0.2847 - val_acc: 0.8865\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 2s 128us/step - loss: 0.1150 - acc: 0.9651 - val_loss: 0.3143 - val_acc: 0.8776\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 2s 124us/step - loss: 0.0980 - acc: 0.9705 - val_loss: 0.3126 - val_acc: 0.8843\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 2s 126us/step - loss: 0.0808 - acc: 0.9763 - val_loss: 0.3853 - val_acc: 0.8653\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 2s 127us/step - loss: 0.0663 - acc: 0.9819 - val_loss: 0.3628 - val_acc: 0.8786\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 2s 139us/step - loss: 0.0561 - acc: 0.9851 - val_loss: 0.3839 - val_acc: 0.8791\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 2s 127us/step - loss: 0.0448 - acc: 0.9889 - val_loss: 0.4155 - val_acc: 0.8768\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 2s 123us/step - loss: 0.0387 - acc: 0.9915 - val_loss: 0.4503 - val_acc: 0.8697\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 2s 126us/step - loss: 0.0301 - acc: 0.9928 - val_loss: 0.4707 - val_acc: 0.8729\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 2s 127us/step - loss: 0.0247 - acc: 0.9948 - val_loss: 0.5030 - val_acc: 0.8718\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 2s 125us/step - loss: 0.0178 - acc: 0.9981 - val_loss: 0.5429 - val_acc: 0.8691\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 2s 125us/step - loss: 0.0169 - acc: 0.9967 - val_loss: 0.5733 - val_acc: 0.8704\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 2s 125us/step - loss: 0.0094 - acc: 0.9994 - val_loss: 0.6233 - val_acc: 0.8641\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 2s 132us/step - loss: 0.0108 - acc: 0.9979 - val_loss: 0.6408 - val_acc: 0.8674\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 2s 133us/step - loss: 0.0072 - acc: 0.9994 - val_loss: 0.6779 - val_acc: 0.8654\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 2s 124us/step - loss: 0.0088 - acc: 0.9979 - val_loss: 0.7015 - val_acc: 0.8647\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "# Batch_size is the number of times it runs through the batch and adds it back\n",
    "history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acc', 'loss', 'val_acc', 'val_loss']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "[u'acc', u'loss', u'val_acc', u'val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This serves as a marker for the originial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Overtraining/overfeeding is where it memorizes the pattern that was set for the network\n",
    "# It memorizes the small patterns and if something falls into its pattern then it\n",
    "# gets labeled as that thing\n",
    "# You can add random noise to fix this problem. It creates a more broad outline so it doesn't\n",
    "# memorize patterns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf() # clears the figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 99us/step - loss: 0.4743 - acc: 0.8206\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 84us/step - loss: 0.2638 - acc: 0.9102\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 84us/step - loss: 0.1993 - acc: 0.9299\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 84us/step - loss: 0.1680 - acc: 0.9406\n",
      "25000/25000 [==============================] - 4s 148us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3250337515449524, 0.87268]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13237198],\n",
       "       [0.9997235 ],\n",
       "       [0.26496774],\n",
       "       ...,\n",
       "       [0.0729683 ],\n",
       "       [0.04766338],\n",
       "       [0.47623575]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First set of changes in parameters\n",
    "# Epochs increased to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.4583 - acc: 0.8140\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 2s 83us/step - loss: 0.2632 - acc: 0.9093\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 2s 85us/step - loss: 0.2008 - acc: 0.9279\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 2s 84us/step - loss: 0.1690 - acc: 0.9383\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 2s 85us/step - loss: 0.1452 - acc: 0.9486\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 2s 94us/step - loss: 0.1291 - acc: 0.9550\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 2s 84us/step - loss: 0.1155 - acc: 0.9604\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 2s 86us/step - loss: 0.1033 - acc: 0.9637\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 2s 86us/step - loss: 0.0938 - acc: 0.9676\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 2s 84us/step - loss: 0.0834 - acc: 0.9724\n",
      "25000/25000 [==============================] - 3s 138us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4383965616607666, 0.86448]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0701666 ],\n",
       "       [0.9999521 ],\n",
       "       [0.77896297],\n",
       "       ...,\n",
       "       [0.11491497],\n",
       "       [0.02344751],\n",
       "       [0.87617725]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second set of changes in parameters\n",
    "# Batch size increased to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 0.5302 - acc: 0.7857\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 2s 88us/step - loss: 0.3408 - acc: 0.8926\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 2s 88us/step - loss: 0.2568 - acc: 0.9172\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 2s 88us/step - loss: 0.2145 - acc: 0.9257\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 2s 89us/step - loss: 0.1827 - acc: 0.9375\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 2s 88us/step - loss: 0.1604 - acc: 0.9456\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 2s 92us/step - loss: 0.1390 - acc: 0.9534\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 2s 90us/step - loss: 0.1292 - acc: 0.9565\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.1157 - acc: 0.9624\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 2s 91us/step - loss: 0.1029 - acc: 0.9674\n",
      "25000/25000 [==============================] - 4s 161us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=1000)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3438275262594223, 0.87432]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14490157],\n",
       "       [0.9999621 ],\n",
       "       [0.6757294 ],\n",
       "       ...,\n",
       "       [0.0976494 ],\n",
       "       [0.03315741],\n",
       "       [0.69416267]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third set of changes in parameters\n",
    "# Batch size back to 512. Epochs equal to 4\n",
    "# sgd optimizer used instead of rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 0.6889 - acc: 0.5428\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 83us/step - loss: 0.6697 - acc: 0.6297\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 96us/step - loss: 0.6406 - acc: 0.7025\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 0.6062 - acc: 0.7518\n",
      "25000/25000 [==============================] - 3s 106us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'sgd',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5922212927246093, 0.76596]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47539118],\n",
       "       [0.639273  ],\n",
       "       [0.617217  ],\n",
       "       ...,\n",
       "       [0.4086302 ],\n",
       "       [0.43364215],\n",
       "       [0.55690205]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third set of changes in parameters\n",
    "# Batch size back to 512. Epochs equal to 4\n",
    "# sgd optimizer used \n",
    "# mean_squared_error loss function used instead of binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 89us/step - loss: 0.2482 - acc: 0.5300\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 82us/step - loss: 0.2427 - acc: 0.5871\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 0.2355 - acc: 0.6392\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 0.2268 - acc: 0.6826\n",
      "25000/25000 [==============================] - 3s 106us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'sgd',\n",
    "             loss = 'mean_squared_error',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.22265447635650634, 0.70572]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5118873 ],\n",
       "       [0.5786984 ],\n",
       "       [0.5430622 ],\n",
       "       ...,\n",
       "       [0.4837125 ],\n",
       "       [0.53345436],\n",
       "       [0.5171001 ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth set of changes uses the originial parameters \n",
    "# except uses the mse loss function instead o binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 90us/step - loss: 0.1444 - acc: 0.8210\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 0.0772 - acc: 0.9099\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 0.0590 - acc: 0.9302\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 0.0481 - acc: 0.9432\n",
      "25000/25000 [==============================] - 3s 108us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'mse',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08540993715763091, 0.884]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19549894],\n",
       "       [0.99909866],\n",
       "       [0.8717751 ],\n",
       "       ...,\n",
       "       [0.1537549 ],\n",
       "       [0.10430457],\n",
       "       [0.6245485 ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fifth set of changes uses the originial parameters \n",
    "# except uses the mse loss function instead of binary_crossentropy\n",
    "# and uses the tanh activation instead of relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 87us/step - loss: 0.1388 - acc: 0.8321\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0693 - acc: 0.9152\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0516 - acc: 0.9356\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0410 - acc: 0.9489\n",
      "25000/25000 [==============================] - 2s 69us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'mse',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09533955956816673, 0.87528]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0640539 ],\n",
       "       [0.9981811 ],\n",
       "       [0.9915187 ],\n",
       "       ...,\n",
       "       [0.19993085],\n",
       "       [0.07901686],\n",
       "       [0.8018413 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sixth set of changes uses the originial parameters \n",
    "# and uses the tanh activation instead of relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 93us/step - loss: 0.4182 - acc: 0.8305\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.2310 - acc: 0.9154\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.1762 - acc: 0.9348\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.1473 - acc: 0.9472\n",
      "25000/25000 [==============================] - 2s 65us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32564479331970214, 0.87672]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07824724],\n",
       "       [0.9980604 ],\n",
       "       [0.80349743],\n",
       "       ...,\n",
       "       [0.07016245],\n",
       "       [0.05840616],\n",
       "       [0.8314956 ]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seventh set of changes uses the originial parameters \n",
    "# and uses the tanh activation instead of relu because that seems to produce better\n",
    "# accuracy. I also have increased the epochs to 10 and lowered the batch size to 412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.4282 - acc: 0.8371\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 1s 57us/step - loss: 0.2337 - acc: 0.9170\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 1s 51us/step - loss: 0.1759 - acc: 0.9366\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 1s 51us/step - loss: 0.1457 - acc: 0.9475\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 1s 52us/step - loss: 0.1262 - acc: 0.9578\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 1s 51us/step - loss: 0.1101 - acc: 0.9642\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 1s 51us/step - loss: 0.0961 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 1s 52us/step - loss: 0.0900 - acc: 0.9724\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 1s 51us/step - loss: 0.0780 - acc: 0.9765\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 1s 53us/step - loss: 0.0732 - acc: 0.9774\n",
      "25000/25000 [==============================] - 2s 65us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=412)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.514736520318985, 0.85712]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03776944],\n",
       "       [0.9987826 ],\n",
       "       [0.95804495],\n",
       "       ...,\n",
       "       [0.10167404],\n",
       "       [0.01266373],\n",
       "       [0.9907823 ]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf() # clears the figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eighth set of changes uses the originial parameters \n",
    "# and uses the tanh activation instead of relu because that seems to produce better\n",
    "# accuracy. I also have increased the epochs to 6 and lowered the batch size to 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03776944],\n",
       "       [0.9987826 ],\n",
       "       [0.95804495],\n",
       "       ...,\n",
       "       [0.10167404],\n",
       "       [0.01266373],\n",
       "       [0.9907823 ]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "25000/25000 [==============================] - 2s 96us/step - loss: 0.4438 - acc: 0.8296\n",
      "Epoch 2/6\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.2480 - acc: 0.9123\n",
      "Epoch 3/6\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.1854 - acc: 0.9327\n",
      "Epoch 4/6\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 0.1512 - acc: 0.9466\n",
      "Epoch 5/6\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.1307 - acc: 0.9550\n",
      "Epoch 6/6\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 0.1131 - acc: 0.9636\n",
      "25000/25000 [==============================] - 2s 67us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=6, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40587328494548797, 0.86176]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eighth set of changes uses the originial parameters \n",
    "# and uses the tanh activation instead of relu because that seems to produce better\n",
    "# accuracy. I also have increased the hidden units used by the layers to 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 0.4025 - acc: 0.8286\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 0.2253 - acc: 0.9118\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 0.1759 - acc: 0.9338\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 0.1515 - acc: 0.9432\n",
      "25000/25000 [==============================] - 2s 72us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(32, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3332366373825073, 0.87564]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12746376],\n",
       "       [0.99945706],\n",
       "       [0.8962241 ],\n",
       "       ...,\n",
       "       [0.10556126],\n",
       "       [0.04144866],\n",
       "       [0.68813205]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nineth set of changes uses the originial parameters \n",
    "# and uses the mse loss function instead of binary_crossentropy\n",
    "# I also have increased the hidden units used by the layers to 32\n",
    "# Am trying to beat [0.08531691110730172, 0.88416] for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 3s 106us/step - loss: 0.1358 - acc: 0.8285\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 85us/step - loss: 0.0714 - acc: 0.9128\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 3s 109us/step - loss: 0.0555 - acc: 0.9321\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 95us/step - loss: 0.0457 - acc: 0.9453\n",
      "25000/25000 [==============================] - 4s 144us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'mse',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09663559941887856, 0.86932]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0910129 ],\n",
       "       [0.99811816],\n",
       "       [0.63224906],\n",
       "       ...,\n",
       "       [0.08758566],\n",
       "       [0.03835934],\n",
       "       [0.3732337 ]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenth set of changes uses the originial parameters \n",
    "# and uses the mse loss function instead of binary_crossentropy\n",
    "# I also have increased the hidden units used by the layers to 64\n",
    "# Am trying to beat [0.08531691110730172, 0.88416] for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 3s 135us/step - loss: 0.1381 - acc: 0.8048\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 3s 119us/step - loss: 0.0696 - acc: 0.9106\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 3s 115us/step - loss: 0.0552 - acc: 0.9301\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 3s 114us/step - loss: 0.0419 - acc: 0.9482\n",
      "25000/25000 [==============================] - 4s 153us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'mse',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09615927561461926, 0.87248]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15405141],\n",
       "       [0.9999713 ],\n",
       "       [0.99364954],\n",
       "       ...,\n",
       "       [0.31035933],\n",
       "       [0.09684984],\n",
       "       [0.7881257 ]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenth set of changes uses the originial parameters \n",
    "# and uses the mse loss function instead of binary_crossentropy\n",
    "# I also have decreasesd the batch size to 412\n",
    "# Am trying to beat [0.08531691110730172, 0.88416] for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 90us/step - loss: 0.1412 - acc: 0.8316\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 0.0738 - acc: 0.9157\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0561 - acc: 0.9328\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 0.0465 - acc: 0.9435\n",
      "25000/25000 [==============================] - 3s 138us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'mse',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=412)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08884503876566886, 0.88]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11540182],\n",
       "       [0.99738544],\n",
       "       [0.796005  ],\n",
       "       ...,\n",
       "       [0.19288963],\n",
       "       [0.06724109],\n",
       "       [0.6405865 ]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11th changed loss to mse and epochs to 3\n",
    "# Am trying to beat [0.08531691110730172, 0.88416] for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 2s 90us/step - loss: 0.1478 - acc: 0.8264\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0750 - acc: 0.9113\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 0.0563 - acc: 0.9325\n",
      "25000/25000 [==============================] - 3s 140us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential() # Sequential is important\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'mse',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=412)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08466435901403427, 0.88536]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16865538],\n",
       "       [0.9974534 ],\n",
       "       [0.73188347],\n",
       "       ...,\n",
       "       [0.14024647],\n",
       "       [0.13007125],\n",
       "       [0.55914146]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
